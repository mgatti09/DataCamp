{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter Two. Linear Regression in TensorFlow\n",
    "\n",
    "Here, you'll use TensorFlow to create a linear model that can predict house prices. You will start by learning how to load and manipulate data in TensorFlow. You'll then learn how to construct loss functions and minimize them to find the optimal parameter values for a linear model. Finally, you'll learn how to reduce the resource constraints of your program by using batch training.\n",
    "\n",
    "> **Topics:**\n",
    "- 1. Input data\n",
    "    - 1.1 Setting the data type\n",
    "    - 1.2 Load data using pandas\n",
    "    - 1.3 Bringing everything together\n",
    "- 2. Loss functions\n",
    "    - 2.1. Loss functions in TensorFlow\n",
    "    - 2.2. Modifying the loss function\n",
    "- 3. Linear regression\n",
    "    - 3.1. Set up a linear regression\n",
    "    - 3.2. Train a linear model\n",
    "    - 3.3. Multiple linear regression\n",
    "- 4. Batch training\n",
    "    - 4.1. Preparing to batch train\n",
    "    - 4.2. Training a linear model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "filepath = '../_datasets/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input data\n",
    "\n",
    "![][01-data]\n",
    "\n",
    "### Importing data for use in TensorFlow\n",
    "- **Data can be imported using `tensorflow`**\n",
    "    - Useful for managing complex pipelines\n",
    "    - Not necessary for this chapter\n",
    "- **Simpler option used in this chapter**\n",
    "- Import data using `pandas`\n",
    "- Convert data to `numpy` array\n",
    "- Use in `tensorflow` without modification\n",
    "\n",
    "### How to import and convert data\n",
    "\n",
    "```Python\n",
    "# Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from csv\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert to numpy array\n",
    "housing = np.array(housing)\n",
    "```\n",
    "\n",
    "- We will focus on data stored in csv format in this chapter\n",
    "- Pandas also has methods for handling data in other formats\n",
    "    - E.g. `read_json()` , `read_html()` , `read_excel()`\n",
    "\n",
    "### Setting the data type\n",
    "```Python \n",
    "# Load KC dataset\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = np.array(housing['waterfront'], np.bool)\n",
    "\n",
    "# Load KC dataset\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = tf.cast(housing['price'], tf.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "```\n",
    "\n",
    "[01-data]:_Docs/01-data.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setting the data type\n",
    "When performing operations in `tensorflow`, you will need to ensure that your choice of data types is valid. For example, let's say you're using the `housing['bedrooms']` column from the King County dataset to define the constant tensor, `bedrooms`. You then want to multiply that tensor by a constant, `scalar`. Given the definitions below, how can you define `bedrooms` to ensure that `scalar`, `bedrooms`, and their product, `product`, have the same data type?\n",
    "```Python\n",
    "scalar = tf.constant(0.1, tf.float32)\n",
    "product = tf.multiply(bedrooms, scalar)\n",
    "```\n",
    "Note that `housing` and `scalar` are available in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=float32, numpy=0.1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tf.constant(0.1)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(filepath+'kc_house_data.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Answers**\n",
    "- [x] bedrooms = tf.cast(housing['bedrooms'], tf.float32)\n",
    "- [ ] bedrooms = tf.cast(housing['bedrooms'], tf.bool)\n",
    "- [ ] bedrooms = tf.cast(tf.float32, housing['bedrooms'])\n",
    "- [ ] bedrooms = tf.constant(housing['bedrooms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data using pandas\n",
    "Before you can train a machine learning model, you must first import data. There are several valid ways to do this, but for now, we will use a simple one-liner from `pandas`: `pd.read_csv()`. Recall from the video that the first argument specifies the path or URL. All other arguments are optional.\n",
    "\n",
    "In this exercise, you will import the King County housing dataset, which we will use to train a linear model later in the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bringing everything together\n",
    "In previous exercises, you loaded data using `pandas` and explored how to set data types using `np.array()` and `tf.cast()`. In this exercise, you will bring everything together, starting where the previous exercise ended: housing is available and pandas has been imported as `pd`. You will import `numpy` and `tensorflow`, and define tensors that are usable in tensorflow using columns in housing with a given data type. Recall that you can select the `price` column, for instance, from `housing` using `housing['price']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss functions\n",
    "\n",
    "### Introduction to loss functions\n",
    "- **Fundamental `tensorflow` operation**\n",
    "    - Used to train a model\n",
    "    - Measure of model \n",
    "- **Higher value -> worse **\n",
    "    - Minimize the loss function\n",
    "    \n",
    "### Common loss functions in TensorFlow\n",
    "- **TensorFlow has operations for common loss functions**\n",
    "    - Mean squared error (MSE)\n",
    "    - Mean absolute error (MAE)\n",
    "    - Huber error\n",
    "- **Loss functions are accessible from `tf.keras.losses()`**\n",
    "    - `tf.keras.losses.mse()`\n",
    "    - `tf.keras.losses.mae()`\n",
    "    - `tf.keras.losses.Huber()`\n",
    "    \n",
    "### Why do we care about loss functions?\n",
    "\n",
    "- **MSE**\n",
    "    - Strongly penalizes outliers\n",
    "    - High sensitivity near minimum\n",
    "- **MAE**\n",
    "    - Scales linearly with size of error\n",
    "    - Low sensitivity near minimum\n",
    "- **Huber**\n",
    "    - Similar to MSE near minimum\n",
    "    - Similar to MAE away from minimum\n",
    "\n",
    "![][02-loss]\n",
    "\n",
    "### Defining a loss function\n",
    "```Python\n",
    "# Define a loss function to compute the MSE\n",
    "def loss_function(intercept, slope, target, features):\n",
    "\n",
    "# Compute the predictions for a linear model\n",
    "predictions = intercept + features*slope\n",
    "\n",
    "# Return the loss\n",
    "return tf.keras.losses.mse(target, predictions)\n",
    "\n",
    "# Compute the loss for given input data and model parameters\n",
    "loss_function(intercept, slope, prices, size)\n",
    "```\n",
    "\n",
    "### Common loss functions\n",
    "\n",
    "| Loss | Name               | Operation             |\n",
    "|------|--------------------|-----------------------|\n",
    "| MSE  | Mean Squared Error | tf.keras.losses.mse() |\n",
    "| MAE  | Mean Absolute Error| tf.keras.losses.mae() |\n",
    "| Huber| Huber Error        |tf.keras.losses.Huber()|\n",
    "\n",
    "\n",
    "### Other loss functions\n",
    "\n",
    "| Loss | Name                          | Operation             |\n",
    "|------|-------------------------------|-----------------------|\n",
    "| MAPE | Mean Absolute Percentage Error| tf.keras.losses.mape()|\n",
    "| MSLE | Mean Squared Logarithmic Error| tf.keras.losses.msle()|\n",
    "\n",
    "[02-loss]:_Docs/02-loss.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loss functions in TensorFlow\n",
    "In this exercise, you will compute the loss using data from the King County housing dataset. You are given a target, `price`, which is a tensor of house prices, and `predictions`, which is a tensor of predicted house prices. You will evaluate the loss function and print out the value of the loss.\n",
    "\n",
    "![][03-mse_mae]\n",
    "\n",
    "You may have noticed that the MAE was much smaller than the MSE, even though `price` and `predictions` were the same. This is because the different loss functions penalize deviations of `predictions` from `price` differently. MSE does not like large deviations and punishes them harshly.\n",
    "\n",
    "[03-mse_mae]:_Docs/03-mse_mae.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modifying the loss function\n",
    "In the previous exercise, you defined a `tensorflow` loss function and then evaluated it once for a set of actual and predicted values. In this exercise, you will compute the loss within another function called `loss_function()`, which first generates predicted values from the data and variables. The purpose of this is to construct a function of the trainable model variables that returns the loss. You can then repeatedly evaluate this function for different variable values until you find the minimum. In practice, you will pass this function to an optimizer in tensorflow. Note that `features` and `target` have been defined and are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target   = np.array([ 2.,  4.,  6.,  8., 10.])\n",
    "features = np.array([1., 2., 3., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = tf.constant(1.0)\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features, target):\n",
    "\t# Define the predicted values\n",
    "\tpredictions = scalar * features\n",
    "    \n",
    "\t# Return the MAE loss\n",
    "\treturn keras.losses.mae(target, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar, features, target).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression\n",
    "\n",
    "### What is a linear regression?\n",
    "\n",
    "![][04-LR]\n",
    "\n",
    "### The linear regression model\n",
    "- A linear regression model assumes a linear relationship:\n",
    "    - $price = intercept + size ∗ slope + error$\n",
    "- This is an example of a univariate regression.\n",
    "    - There is only one feature, `size` .\n",
    "- Multiple regression models have more than one feature.\n",
    "    - E.g. `size` and `location`\n",
    "    \n",
    "### Linear regression in TensorFlow\n",
    "\n",
    "```Python\n",
    "# Define the targets and features\n",
    "price = np.array(housing['price'], np.float32)\n",
    "size = np.array(housing['sqft_living'], np.float32)\n",
    "\n",
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(0.1, np.float32)\n",
    "slope = tf.Variable(0.1, np.float32)\n",
    "\n",
    "# Compute the predicted values and loss function\n",
    "def loss_function(intercept, slope, size, price):\n",
    "    predictions = intercept + size*slope\n",
    "    return tf.keras.losses.mse(price, predictions)\n",
    "\n",
    "# Define an optimization operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Minimize the loss function and print the loss\n",
    "for j in range(1000):\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, size, price), var_list=[intercept, slope])\n",
    "    print(loss_function(intercept, slope, size, price))\n",
    "    \n",
    "# Print the trained parameters\n",
    "print(intercept.numpy(), slope.numpy())\n",
    "```\n",
    "\n",
    "[04-LR]:_Docs/04-LR.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up a linear regression\n",
    "A univariate linear regression identifies the relationship between a single feature and the target tensor. In this exercise, we will use the size of a property's lot and that property's price. Just as we discussed in the video, we will take the natural logarithms of both tensors, which are available as `price_log` and `lot_size_log`.\n",
    "\n",
    "In this exercise, you will define the variables to train and the loss function. You will then evaluate the loss function for two different values of `intercept` and `slope`. Remember that the target value is given by `intercept + features*slope + error`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_log = np.log(housing.price)\n",
    "lot_size_log = np.log(housing.sqft_lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(145.44653034728253, shape=(), dtype=float64)\n",
      "tf.Tensor(71.86599398430205, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(0.1, tf.float32, name = 'intercept')\n",
    "slope = tf.Variable(0.1, tf.float32, name = 'slope')\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(p_intercept, p_slope):\n",
    "\t# Set the predicted values\n",
    "\tpred_price_log = p_intercept + lot_size_log * p_slope \n",
    "    \n",
    "    # Return the MSE loss\n",
    "\treturn keras.losses.mse(price_log, pred_price_log)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1))\n",
    "print(loss_function(0.1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a linear model\n",
    "In this exercise, we will pick up where the previous exercise ended. The intercept and slope, `intercept` and `slope`, have been defined and initialized. Additionally, a function has been defined, `loss_function(intercept, slope)`, which computes the loss using the data and model variables.\n",
    "\n",
    "You will now define an optimization operation as `opt`. You will then train a univariate linear model by minimizing the loss to find the optimal values of `intercept` and `slope`. Note that the `opt` operation will try to move closer to the optimum with each step, but will require many steps to find it. Thus, you must repeatedly execute the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 18:32:52.261794 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.287403 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.300400 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.321458 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.344517 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.366585 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.381625 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.392654 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.404689 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.415748 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.64774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:52.426744 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.440783 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.451348 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.462344 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.471876 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.482905 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.496975 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.507972 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.517024 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.527028 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.536077 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.547075 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.557136 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.568171 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.578222 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.591231 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.603297 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.614291 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.624319 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.634378 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.644374 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.655405 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.665066 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.675092 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.688127 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.697149 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.706174 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.715229 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.725224 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.734283 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.746285 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.757314 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.766339 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.776365 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.785391 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.795425 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.806448 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.818478 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.828505 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.838562 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.847588 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.857086 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.866366 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.875355 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.884380 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.894406 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.903430 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.913457 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.922482 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.931539 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.941533 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.951064 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.963097 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.972252 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.981277 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:52.991304 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.001362 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.011366 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.020381 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.029407 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.039432 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.048963 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.058489 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.068466 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.078494 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.087522 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:53.097543 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.107569 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.117596 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.129662 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.138653 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.149683 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.162718 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.172362 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.182422 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.194422 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.206452 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.217481 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.226509 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.237545 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.249105 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.258630 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.268662 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.279725 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.288715 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.297771 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.307798 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.316789 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.326817 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.335873 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.345900 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.362447 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.371631 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.381623 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.391650 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.399704 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.408696 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.418724 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.428750 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.438775 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.447799 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.460334 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.469905 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.478930 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.488924 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.497951 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.506972 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.515996 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.524054 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.533041 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.541062 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2739028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:53.550591 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.559616 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.567722 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.577702 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.588736 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.610864 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.632883 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.652909 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.672010 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.694024 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.715083 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.738178 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.759202 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.784168 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.799206 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.811237 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.823270 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.836302 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.848364 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.860915 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.873455 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.886487 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.898554 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.910553 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.922584 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.935621 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.948687 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.962714 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.974671 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:53.988709 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.003746 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.016782 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.030818 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.044856 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.058398 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.071937 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.084995 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.100011 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.113045 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.125113 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.137110 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.149177 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.161217 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.173217 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.185281 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.198279 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.210349 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.222380 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.234413 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.246410 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.258483 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.271170 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.283200 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.295266 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.307262 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.320332 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.332332 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.344363 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.356936 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.368471 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.380503 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.393502 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.405568 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.417567 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.429599 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.442669 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:54.458216 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.481749 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.514878 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.543961 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.568066 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.593093 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.618154 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.644262 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.670353 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.694467 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.719483 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.747555 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.773640 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.793733 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.822768 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.838813 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.854862 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.873440 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.891491 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.909540 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.926584 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.943625 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.960208 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.977254 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:54.993296 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.012351 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27243558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:55.028431 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.046442 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.062563 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.078139 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.094181 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.109187 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.120217 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.130243 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.138264 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.148291 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.157352 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.166910 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.175404 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.184458 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.194455 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.203479 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.212533 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.221526 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.231553 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.247595 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.267194 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.284612 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.302654 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.320708 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.338708 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.355259 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.366817 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.377803 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.397904 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.425983 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.452049 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.477676 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.501701 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.532779 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.551866 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.569925 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.588007 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.606021 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.624066 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.636098 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.648133 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.667228 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.693263 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.721302 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.750408 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.768969 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.790447 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.807491 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.830552 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.846599 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.874687 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.890732 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.908778 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.927870 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.944873 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.960922 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.976035 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:55.992040 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.010088 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.027137 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.043179 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.068348 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.093456 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.112545 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.129582 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.144626 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:56.160710 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.176785 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.191797 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.216905 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.243939 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.265503 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.283098 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.301135 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.319194 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.338243 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.365292 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.395387 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.422456 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.451535 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.473425 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.492437 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.505503 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.517534 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.527560 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.536553 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.546582 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.556112 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.571656 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.581715 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.589703 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.599731 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.609757 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.619784 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.631815 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.641842 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.650898 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.665411 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.674938 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.685001 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.696997 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.708029 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.718086 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.729118 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.741114 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.755656 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27243552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:56.768690 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.782232 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.794263 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.803285 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.812310 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.821336 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.831390 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.840384 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.848438 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.857965 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.867022 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.875670 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.885701 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.906756 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.927849 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.949870 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.972036 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:56.994095 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.014103 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.035207 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.056224 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.076787 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.098845 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.118898 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.139952 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.157501 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.170536 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.184993 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.198026 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.215039 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.228110 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.241107 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.255656 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.269693 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.283849 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.296849 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.309885 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.323922 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.337960 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.351031 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.368552 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.396133 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.413213 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.432229 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.451277 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.470338 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.491316 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.511335 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.525372 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.539408 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.552443 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.566985 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.581529 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.594564 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.607600 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.621637 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.634669 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.645698 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.660239 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.670268 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.678707 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.688734 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.696755 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.705815 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.714835 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.723858 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:57.732882 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.742878 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.753940 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.762966 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.771466 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.780014 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.789008 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.798032 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.807089 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.816110 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.825103 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.833161 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.842180 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.851207 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.860264 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.868784 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.884274 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.893297 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.901317 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.911345 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.919332 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.928393 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.937381 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.946440 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.955429 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.963986 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.971975 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.982110 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:57.990098 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.000157 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.009179 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.018205 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.027197 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.036219 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.045244 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.054059 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.063587 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27243546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:58.072611 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.081636 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.091694 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.099718 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.108743 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.116764 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.127794 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.136819 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.145838 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.154831 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.163893 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.172415 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.181945 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.190968 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.198990 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.215084 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.233094 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.250170 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.269262 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.286804 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.306906 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.330948 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.344956 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.359001 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.373658 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.388699 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.403736 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.420782 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.436824 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.453868 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.468982 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.484029 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.501072 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.516109 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.531119 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.545156 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.563275 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.578250 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.592287 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.607325 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.622338 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.636374 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.653416 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.669970 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.694540 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.709582 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.729633 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.746683 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.764231 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.788804 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.803845 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.823899 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.837934 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.849964 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.863503 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.876041 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.888073 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.900105 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.913140 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.930187 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.944221 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.960269 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.972303 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:58.984338 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.007398 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.017427 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 18:32:59.026449 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.041490 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.051517 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.063556 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.072578 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.081639 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.092669 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.101660 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.111718 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.120712 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.129769 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n",
      "W0623 18:32:59.138760 23760 optimizer_v2.py:979] Gradients does not exist for variables ['slope:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an adam optimizer\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(500):\n",
    "\t# Apply minimize, pass the loss function, and supply the variables\n",
    "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "\t# Print every 100th value of the loss    \n",
    "\tif j % 100 == 0:\n",
    "\t\tprint(loss_function(intercept, slope).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multiple linear regression\n",
    "In most cases, performing a univariate linear regression will not yield a model that is useful for making accurate predictions. You will instead want to include multiple features in your linear model. This technique is referred to as multiple linear regression.\n",
    "\n",
    "In this exercise, you will set up a multiple linear regression. You will use `price_log` as your target and `lot_size_log` and `bedrooms` as your features. Each of these tensors has been defined and is available. You will also switch from using the the mean squared error loss to the mean absolute error loss: `keras.losses.mae()`. Finally, the predicted values are computed as follows: `intercept + feature_1*slope_1 + feature_2*slope_2`.\n",
    "\n",
    "```Python\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope_1, slope_2):\n",
    "\t# Set the predicted values\n",
    "\tpred_price_log = intercept + lot_size_log*slope_1 + bedrooms*slope_2  \n",
    "  \n",
    "\t# Use the mean absolute error loss\n",
    "\treturn keras.losses.mae(price_log, pred_price_log)\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "\topt.minimize(lambda: loss_function(intercept, slope_1, slope_2), var_list=[intercept, slope_1, slope_2])\n",
    "\tprint_results(intercept, slope_1, slope_2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch training\n",
    "\n",
    "### What is batch training?\n",
    "\n",
    "![][05-batch]\n",
    "\n",
    "### The chunksize parameter\n",
    "- `pd.read_csv()` allows us to load data in batches\n",
    "    - Avoid loading entire dataset\n",
    "    - `chunksize` parameter provides batch size\n",
    "\n",
    "```Python\n",
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_housing.csv', chunksize=100):\n",
    "    # Extract price column\n",
    "    price = np.array(batch['price'], np.float32)\n",
    "    # Extract size column\n",
    "    size = np.array(batch['size'], np.float32)\n",
    "```\n",
    "\n",
    "### Training a linear model in batches\n",
    "```Python\n",
    "# Import tensorflow, pandas, and numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define trainable variables\n",
    "intercept = tf.Variable(0.1, tf.float32)\n",
    "slope = tf.Variable(0.1, tf.float32)\n",
    "\n",
    "# Compute predicted values and return loss function\n",
    "def loss_function(intercept, slope, features, target):\n",
    "    predictions = intercept + features*slope\n",
    "    return tf.keras.losses.mse(target, predictions)\n",
    "\n",
    "# Define optimization operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Load the data in batches from pandas\n",
    "for batch in pd.read_csv('kc_housing.csv', chunksize=100):\n",
    "    # Extract the target and feature columns\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "    size_batch = np.array(batch['lot_size'], np.float32)\n",
    "    # Minimize the loss function\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, size_batch, price_batch), var_list=[intercept, slope])\n",
    "\n",
    "    # Print parameter values\n",
    "print(intercept.numpy(), slope.numpy())\n",
    "```\n",
    "\n",
    "[05-batch]:_Docs/05-batch.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparing to batch train\n",
    "Before we can train a linear model in batches, we must first define variables, a loss function, and an optimization operation. In this exercise, we will prepare to train a model that will predict `price_batch`, a batch of house prices, using `lot_size_batch`, a batch of lot sizes in square feet. In contrast to the previous lesson, we will do this by loading batches of data using pandas, converting it to numpy arrays, and then using it to minimize the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(10.0, tf.float32)\n",
    "slope = tf.Variable(0.5, tf.float32)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, features, target):\n",
    "\t# Define the predicted values\n",
    "\tpredictions = intercept + slope * features\n",
    "    \n",
    " \t# Define the MSE loss\n",
    "\treturn keras.losses.mse(predictions, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training a linear model in batches\n",
    "In this exercise, we will train a linear regression model in batches, starting where we left off in the previous exercise. We will do this by stepping through the dataset in batches and updating the model's variables, `intercept` and `slope`, after each step. This approach will allow us to train with datasets that are otherwise too large to hold in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217888 0.7016\n"
     ]
    }
   ],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv(filepath+'kc_house_data.csv', chunksize=100):\n",
    "\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "    \n",
    "\t# Extract the price values for the current batch\n",
    "\tprice_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "\t# Complete the loss, fill in the variable list, and minimize\n",
    "\topt.minimize(lambda: loss_function(intercept, slope, size_batch, price_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
