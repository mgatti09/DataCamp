{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter Four. Defining neural networks with Keras\n",
    "\n",
    "In the final chapter, you'll use high-level APIs in TensorFlow to train a sign language letter classifier. You will use both the sequential and functional Keras APIs to train, validate, and evaluate models. You will also learn how to use the Estimators API to streamline the model definition and training process and to avoid errors.\n",
    "\n",
    "> **Topics:**\n",
    "- 1. Defining neural networks with Keras\n",
    "    - 1.1 The sequential model in Keras\n",
    "    - 1.2 Compiling a sequential model\n",
    "    - 1.3 Defining a multiple input model\n",
    "- 2. Training and validation with Keras\n",
    "    - 2.1. Training with Keras\n",
    "    - 2.2. Metrics and validation with Keras\n",
    "    - 2.3 Overfitting detection\n",
    "    - 2.4 Evaluating models\n",
    "- 3. Training models with the Estimators API\n",
    "    - 3.1. Preparing to train with Estimators\n",
    "    - 3.2. Defining Estimators\n",
    "- 4. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras, Variable, ones, matmul\n",
    "\n",
    "filepath = '../_datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining Neural Networks with Keras\n",
    "\n",
    "### Classifying sign language letters\n",
    "\n",
    "![][01-sign_language_letters]\n",
    "\n",
    "### The sequential API\n",
    "\n",
    "![][02-sequential_API]\n",
    "\n",
    "- Input layer\n",
    "- Hidden layers\n",
    "- Output layer\n",
    "- Ordered in sequence\n",
    "\n",
    "### Building a sequential model\n",
    "```Python\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define first hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "# Define second hidden layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Define output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "### The functional API\n",
    "\n",
    "![][03-functional_API]\n",
    "\n",
    "### Using the functional API\n",
    "```Python\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define model 1 input layer shape\n",
    "model1_inputs = tf.keras.Input(shape=(28*28,))\n",
    "\n",
    "# Define model 2 input layer shape\n",
    "model2_inputs = tf.keras.Input(shape=(10,))\n",
    "\n",
    "# Define layer 1 for model 1\n",
    "model1_layer1 = tf.keras.layers.Dense(12, activation='relu')(model1_inputs)\n",
    "\n",
    "# Define layer 2 for model 1\n",
    "model1_layer2 = tf.keras.layers.Dense(4, activation='softmax')(model1_layer1)\n",
    "\n",
    "# Define layer 1 for model 2\n",
    "model2_layer1 = tf.keras.layers.Dense(8, activation='relu')(model2_inputs)\n",
    "\n",
    "# Define layer 2 for model 2\n",
    "model2_layer2 = tf.keras.layers.Dense(4, activation='softmax')(model2_layer1)\n",
    "\n",
    "# Merge model 1 and model 2\n",
    "merged = tf.keras.layers.add([model1_layer2, model2_layer2])\n",
    "\n",
    "# Define a functional model\n",
    "model = tf.keras.Model(inputs=[model1_inputs, model2_inputs], outputs=merged)\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "[01-sign_language_letters]:_Docs/01-sign_language_letters.png\n",
    "[02-sequential_API]:_Docs/02-sequential_API.png\n",
    "[03-functional_API]:_Docs/03-functional_API.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The sequential model in Keras\n",
    "In chapter 3, we used components of the `keras` API in `tensorflow` to define a neural network, but we stopped short of using its full capabilities to streamline model definition and training. In this exercise, you will use the `keras` sequential model API to define a neural network that can be used to classify images of sign language letters. You will also use the `.summary()` method to print the model's architecture, including the shape and number of parameters associated with each layer.\n",
    "\n",
    "Note that the images were reshaped from (28, 28) to (784,), so that they could be used as inputs to a dense layer. Additionally, note that `keras` has been imported from `tensorflow` for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,732\n",
      "Trainable params: 12,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've defined a model, but we haven't compiled it. ***The compilation step in `keras` allows us to set the optimizer, loss function, and other useful training parameters in a single line of code***. Furthermore, the `.summary()` method allows us to view the model's architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compiling a sequential model\n",
    "In this exercise, you will work towards classifying letters from the Sign Language MNIST dataset; however, you will adopt a different network architecture than what you used in the previous exercise. There will be fewer layers, but more nodes. Additionally, you will compile the model to use the `adam` optimizer and the `categorical_crossentropy` loss. You will also use a method in `keras` to summarize your model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Defining a multiple input model\n",
    "In some cases, the **sequential API** will not be sufficiently flexible to accommodate your desired model architecture and you will need to use the **functional API** instead. ***If, for instance, you want to train two models with different architectures jointly, you will need to use the functional API to do this***. In this exercise, we will see how to do this. We will also use the `.summary()` method to examine the joint model's architecture.\n",
    "\n",
    "Note that `keras` has been imported from `tensorflow` for you. Additionally, the input layers of the first and second models have been defined as `m1_inputs` and `m2_inputs`, respectively. Note that the two models have the same architecture, but one of them uses a `sigmoid` activation in the first layer and the other uses a `relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 784), dtype=float32)\n",
      "Tensor(\"input_2:0\", shape=(None, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "m1_inputs = tf.keras.layers.Input(shape=(28*28,))\n",
    "m2_inputs = tf.keras.layers.Input(shape=(28*28,))\n",
    "\n",
    "print(m1_inputs)\n",
    "print(m2_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 12)           9420        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           9420        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            52          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            52          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 4)            0           dense_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,944\n",
      "Trainable params: 18,944\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `.summary()` method yields a new column: `connected to`. This column tells you how layers connect to each other within the network. We can see that `dense_2`, for instance, is connected to the `input_2` layer. We can also see that the `add` layer, which merged the two models, connected to both `dense_1` and `dense_3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and validation with Keras\n",
    "\n",
    "### Overview of training and evaluation\n",
    "1. Load and clean data\n",
    "2. Define model\n",
    "3. Train and validate model\n",
    "4. Evaluate model\n",
    "\n",
    "### How to train a model\n",
    "\n",
    "```Python\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the hidden layer\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Train model\n",
    "model.fit(image_features, image_labels)\n",
    "```\n",
    "\n",
    "### The fit() operation\n",
    "- Required arguments\n",
    "    - `features`\n",
    "    - `labels`\n",
    "- Many optional arguments\n",
    "    - `batch_size`\n",
    "    - `epochs`\n",
    "    - `validation_split`\n",
    "\n",
    "### Batch size and epochs\n",
    "\n",
    "- The numbers of examples in each batch is the **batch size**.\n",
    "- The number of times you train on the full set of batches is called **numbers of epochs**\n",
    "- In the image the batch size is 5 and the number of epochs is 2.\n",
    "\n",
    "![][04-Batches_epochs]\n",
    "\n",
    "### Performing validation\n",
    "\n",
    "- The `validation_split` parameter it divide the data in two parts. \n",
    "    - The first part is the train set\n",
    "    - The second part is the validation set\n",
    "- Defining `validation_split = 0.20` means 20% of the data will be for validation   \n",
    "\n",
    "![][05-validation]\n",
    "\n",
    "```Python\n",
    "# Train model with validation split\n",
    "model.fit(features, labels, epochs=10, validation_split=0.20)\n",
    "```\n",
    "\n",
    "- In the next image we can see the training loss and the evaluation loss separately.\n",
    "- If the training loss becomes substantially lower than the evaluation loss, is a clear indication the model is **overfitting**. To avoid overfittig we could: \n",
    "    - Terminate the training process before that point or\n",
    "    - add regularization or\n",
    "    - dropout    \n",
    "\n",
    "![][06-validation]\n",
    "\n",
    "### Changing the metric\n",
    "```Python\n",
    "# Recomile the model with the accuracy metric\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with validation split\n",
    "model.fit(features, labels, epochs=10, validation_split=0.20)\n",
    "```\n",
    "\n",
    "![][07-metric]\n",
    "\n",
    "### The evaluation() operation\n",
    "\n",
    "- It's always a good idea to split off a test set before you begin to train and validate, **this way you can check the performance on the test set and the end of the training process**.\n",
    "- Since you may tune model parameters in response to validation set performance, **using a separate test set will provide you with further assurance that you haven't overfitted**.\n",
    "\n",
    "![][08-evaluation]\n",
    "\n",
    "```Python\n",
    "# Evaluate the test set\n",
    "model.evaluate(test)\n",
    "```\n",
    "\n",
    "[04-Batches_epochs]:_Docs/04-Batches_epochs.png\n",
    "[05-validation]:_Docs/05-validation.png\n",
    "[06-validation]:_Docs/06-validation.png\n",
    "[07-metric]:_Docs/07-metric.png\n",
    "[08-evaluation]:_Docs/08-evaluation.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
